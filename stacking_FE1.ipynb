{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def process_predictions(file_path):\n",
    "    \"\"\"\n",
    "    Processes predictions stored in a CSV file.\n",
    "    \n",
    "    - Loads the DataFrame from the given CSV file.\n",
    "    - Transforms the DataFrame from wide to long format using 'melt'.\n",
    "    - Generates a new 'new_session_id' by combining 'session_id' and 'question_number'.\n",
    "    - Extracts the 'question_number' and 'session_id' from 'new_session_id' as new columns.\n",
    "    - Returns the processed DataFrame with 'new_session_id', 'pred', 'q', and 'session'.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path to the CSV file containing the predictions data.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: Processed DataFrame with relevant columns.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_melt = df.melt(id_vars='session_id', var_name='question_number', value_name='pred')\n",
    "    df_melt['new_session_id'] = df_melt.apply(lambda row: f\"{row['session_id']}_q{row['question_number']}\", axis=1)\n",
    "    df = df_melt[['new_session_id', 'pred']].copy()\n",
    "    df['q'] = df['new_session_id'].apply(lambda x: int(x[x.index('_')+2:]))\n",
    "    df['session'] = df['new_session_id'].apply(lambda x: x.split('_')[0])\n",
    "    return df\n",
    "\n",
    "def f1_score_macro_for_thresholds(y_true, y_pred_prob, thresholds):\n",
    "    \"\"\"\n",
    "    Calculate macro-averaged F1 score for binary classification at different probability thresholds.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (numpy.ndarray): The true binary labels.\n",
    "    y_pred_prob (numpy.ndarray): The predicted probabilities for the positive class.\n",
    "    thresholds (numpy.ndarray): An array of probability thresholds to apply.\n",
    "\n",
    "    Returns:\n",
    "    float: Macro-averaged F1 score for each threshold.\n",
    "    \"\"\"\n",
    "    y_pred_binary = (y_pred_prob > thresholds).astype(int)\n",
    "    score = f1_score(y_true, y_pred_binary, average=\"macro\")\n",
    "    return score\n",
    "\n",
    "def optimize_thresholds(y_true, y_pred_prob, method=\"Powell\"):\n",
    "    \"\"\"\n",
    "    Optimize probability thresholds for binary classification to maximize the macro-averaged F1 score.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (numpy.ndarray): The true binary labels.\n",
    "    y_pred_prob (numpy.ndarray): The predicted probabilities for the positive class.\n",
    "    method (str, optional): The optimization method to use (default is \"Powell\").\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Optimal probability thresholds for each label.\n",
    "    \"\"\"\n",
    "    n_labels = y_pred_prob.shape[1]\n",
    "    init_thresholds = np.full(n_labels, 0.6)\n",
    "\n",
    "    objective = lambda thresholds: -f1_score_macro_for_thresholds(y_true, y_pred_prob, thresholds)\n",
    "    result = minimize(objective, init_thresholds, bounds=[(0, 1)] * n_labels, method=method)\n",
    "\n",
    "    return result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the predictions\n",
    "gbt_preds = process_predictions('data/GBT_FE1_predictions.csv')\n",
    "light_preds = process_predictions('data/lightGBM_FE1_predictions.csv')\n",
    "mlp_preds = process_predictions('data/MLP_FE1_predictions.csv')\n",
    "xg_preds = process_predictions('data/XGBoost_FE1_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72025532, 0.74339731, 0.73632896, 0.72240227],\n",
       "       [0.82191908, 0.7690637 , 0.73775929, 0.80756241],\n",
       "       [0.79695243, 0.77578528, 0.73632896, 0.77131236],\n",
       "       ...,\n",
       "       [0.96105742, 0.95361682, 0.94810164, 0.94596398],\n",
       "       [0.97004759, 0.97108219, 0.94344366, 0.95030183],\n",
       "       [0.9036718 , 0.90467326, 0.94810164, 0.86856925]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stack the predictions\n",
    "ensemble_input = np.stack([\n",
    "    gbt_preds['pred'].values,\n",
    "    light_preds['pred'].values,\n",
    "    mlp_preds['pred'].values,\n",
    "    xg_preds['pred'].values\n",
    "], axis=1)\n",
    "\n",
    "display(ensemble_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_session_id</th>\n",
       "      <th>pred</th>\n",
       "      <th>q</th>\n",
       "      <th>session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200_q0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20090312431273200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312433251036_q0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20090312433251036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312455206810_q0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20090312455206810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090313091715820_q0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20090313091715820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090313571836404_q0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20090313571836404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424111</th>\n",
       "      <td>22100215342220508_q17</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>22100215342220508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424112</th>\n",
       "      <td>22100215460321130_q17</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>22100215460321130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424113</th>\n",
       "      <td>22100217104993650_q17</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>22100217104993650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424114</th>\n",
       "      <td>22100219442786200_q17</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>22100219442786200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424115</th>\n",
       "      <td>22100221145014656_q17</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>22100221145014656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>424116 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               new_session_id  pred   q            session\n",
       "0        20090312431273200_q0     0   0  20090312431273200\n",
       "1        20090312433251036_q0     0   0  20090312433251036\n",
       "2        20090312455206810_q0     0   0  20090312455206810\n",
       "3        20090313091715820_q0     0   0  20090313091715820\n",
       "4        20090313571836404_q0     0   0  20090313571836404\n",
       "...                       ...   ...  ..                ...\n",
       "424111  22100215342220508_q17     0  17  22100215342220508\n",
       "424112  22100215460321130_q17     0  17  22100215460321130\n",
       "424113  22100217104993650_q17     0  17  22100217104993650\n",
       "424114  22100219442786200_q17     0  17  22100219442786200\n",
       "424115  22100221145014656_q17     0  17  22100221145014656\n",
       "\n",
       "[424116 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oof = xg_preds.copy()\n",
    "oof[\"pred\"] = 0\n",
    "display(oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the true labels\n",
    "true = pd.read_csv('data/true.csv')\n",
    "true_melt = true.melt(id_vars='session_id', var_name='question_number', value_name='correct')\n",
    "correct_labels = true_melt[\"correct\"]\n",
    "correct_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_models = []\n",
    "mlp_models = []\n",
    "lr_preds = xg_preds['pred'].copy()\n",
    "MLP_preds = xg_preds['pred'].copy()\n",
    "final_preds = xg_preds['pred'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models with each question\n",
    "for q in range(0,18):\n",
    "    idx = oof[oof[\"q\"] == q]\n",
    "    idx = idx.index\n",
    "    _ensemble_input = ensemble_input[idx]\n",
    "    _target = correct_labels[idx]\n",
    "\n",
    "    lr_model = LogisticRegression(random_state=42)\n",
    "    lr_model.fit(_ensemble_input, _target)\n",
    "    lr_models.append(lr_model)\n",
    "\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(10,), max_iter=500, random_state=42)\n",
    "    mlp.fit(_ensemble_input, _target)\n",
    "    mlp_models.append(mlp)\n",
    "\n",
    "    lr_p = lr_model.predict_proba(_ensemble_input)[:, 1]\n",
    "    mlp_p = mlp.predict_proba(_ensemble_input)[:, 1]\n",
    "    final_p = (lr_p + mlp_p) / 2\n",
    "\n",
    "    lr_preds[idx] = lr_p\n",
    "    MLP_preds[idx] = mlp_p\n",
    "    final_preds[idx] = final_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the models in pickle\n",
    "with open(\"data/LR_FE1_models.pkl\", \"wb\") as f:\n",
    "    pickle.dump(lr_models, f)\n",
    "with open(\"data/MLP_for_STACK_FE1_models.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mlp_models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thrs:  [0.63222912]\n",
      "Avg F1 Score: 0.6730503782258368\n"
     ]
    }
   ],
   "source": [
    "# Print the results of LR\n",
    "lr_preds = lr_preds.to_numpy().reshape(-1, 1).astype(\"float32\")\n",
    "thr = optimize_thresholds(correct_labels, lr_preds, \"Powell\")\n",
    "f1 = f1_score_macro_for_thresholds(correct_labels, lr_preds, thr)\n",
    "\n",
    "print('thrs: ', thr)\n",
    "print('Avg F1 Score:', np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thrs:  [0.63086521]\n",
      "Avg F1 Score: 0.672959947099705\n"
     ]
    }
   ],
   "source": [
    "# Print the results of MLP\n",
    "MLP_preds = MLP_preds.to_numpy().reshape(-1, 1).astype(\"float32\")\n",
    "thr = optimize_thresholds(correct_labels, MLP_preds, \"Powell\")\n",
    "f1 = f1_score_macro_for_thresholds(correct_labels, MLP_preds, thr)\n",
    "\n",
    "print('thrs: ', thr)\n",
    "print('Avg F1 Score:', np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thrs:  [0.63238657]\n",
      "Avg F1 Score: 0.673147537955282\n"
     ]
    }
   ],
   "source": [
    "# Print the results of LR and MLP in average\n",
    "final_preds = final_preds.to_numpy().reshape(-1, 1).astype(\"float32\")\n",
    "thr = optimize_thresholds(correct_labels, final_preds, \"Powell\")\n",
    "f1 = f1_score_macro_for_thresholds(correct_labels, final_preds, thr)\n",
    "\n",
    "print('thrs: ', thr)\n",
    "print('Avg F1 Score:', np.mean(f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
